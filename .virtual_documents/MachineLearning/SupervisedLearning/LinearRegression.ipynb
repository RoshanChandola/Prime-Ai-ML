import pandas as pd 
import seaborn as sns


insurance_data = pd.read_csv("insurance.csv")


insurance_data


# visulaize

sns.scatterplot(x=insurance_data["bmi"], y=insurance_data["charges"], hue=insurance_data["smoker"])


X=insurance_data.drop(columns = ["charges", "region"])
y=insurance_data["charges"]

X["sex"] = X["sex"].map({"female":1, "male": 0})
X["smoker"] = X["smoker"].map({"yes":1, "no": 0})



X.head()


#train test split method of scikit learn
from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=
    42)


X_test.head()


#train model
from sklearn.linear_model import LinearRegression

model= LinearRegression()
model.fit(X_train, y_train)


#predict values
y_pred= model.predict(X_test)


y_pred


y_test


#evaluate
from sklearn.metrics import r2_score

r2= r2_score(y_test, y_pred)
print("r-squared:", r2)

n= X_test.shape[0]
p= X_test.shape[1]

adj_r2 = 1 - ((1-r2) * (n-1) / (n-p-1))
print("adjusted r- squared :", adj_r2)



insurance_data.head()


# one Hot Encoding

X=insurance_data.drop(columns = ["charges"])
y=insurance_data["charges"]

X=pd.get_dummies(X,columns=["region"], drop_first=True, dtype= int)# for hadling multicollinearity problems o
#dummy variable trap 

X["sex"] = X["sex"].map({"female":1, "male": 0})
X["smoker"] = X["smoker"].map({"yes":1, "no": 0})


X.head()


#interaction features
X=insurance_data.drop(columns = ["charges"])
y=insurance_data["charges"]

X=pd.get_dummies(X,columns=["region"], drop_first=True, dtype= int)# for hadling multicollinearity problems o
#dummy variable trap 

X["sex"] = X["sex"].map({"female":1, "male": 0})
X["smoker"] = X["smoker"].map({"yes":1, "no": 0})
X["age_smoker"] = X["age"] * X["smoker"]
X["bmi_smoker"] = X["bmi"]* X["smoker"]


X.head()


X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42)

model = LinearRegression()
model.fit(X_train, y_train)
y_pred = model.predict(X_test)

r2= r2_score(y_test, y_pred)
print("r-squared:", r2)


# underfit & overfit
# r2 training is low and r2 testing is also low - underfit
# r2 training >> r2 testing is also low - underfit

y_train_pred = model.predict(X_train)
r2_train = r2_score(y_train, y_train_pred)
print("Training data r2:", r2_train)
print("test data r2 :", r2)


insurance_data.shape
